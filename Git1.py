import time
import pandas as pd
import os
import datetime
import re
import random
import yaml
import json
import smtplib
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.image import MIMEImage

# --- SELENIUM STANDARD IMPORTS ---
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, ElementClickInterceptedException, NoSuchElementException
from selenium.webdriver.common.action_chains import ActionChains
from webdriver_manager.chrome import ChromeDriverManager # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Driver ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

from dotenv import load_dotenv
from thefuzz import fuzz 
from dateutil.relativedelta import relativedelta 
import logging
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeRemainingColumn, TimeElapsedColumn, TaskProgressColumn
from rich.theme import Theme

# --- SETUP & CONFIG ---
try:
    from fake_useragent import UserAgent
except ImportError:
    UserAgent = None

logging.getLogger("WDM").setLevel(logging.CRITICAL) # ‡∏õ‡∏¥‡∏î Log ‡∏Ç‡∏≠‡∏á Webdriver Manager

ENV_PATH = "User.env"
COMPETITORS_PATH = "compe.yaml"
CLIENTS_PATH = "co.yaml"
TIER1_PATH = "tier1.yaml"
RESUME_IMAGE_FOLDER = "resume_images" 
EMAIL_USE_HISTORY = False        

rec_env = os.getenv("EMAIL_RECEIVER")
MANUAL_EMAIL_RECEIVERS = [rec_env] if rec_env else []

custom_theme = Theme({"info": "dim cyan", "warning": "yellow", "error": "bold red", "success": "bold green"})
console = Console(theme=custom_theme)

load_dotenv(ENV_PATH, override=True)
MY_USERNAME = os.getenv("JOBTHAI_USER")
MY_PASSWORD = os.getenv("JOBTHAI_PASS")

G_SHEET_KEY_JSON = os.getenv("G_SHEET_KEY")
G_SHEET_NAME = os.getenv("G_SHEET_NAME")

TIER1_TARGETS = {}
if os.path.exists(TIER1_PATH):
    try:
        with open(TIER1_PATH, "r", encoding="utf-8") as f:
            yaml_data = yaml.safe_load(f)
            if yaml_data:
                for k, v in yaml_data.items():
                    if v:
                        if isinstance(v, list): TIER1_TARGETS[k] = [str(x).strip() for x in v]
                        else: TIER1_TARGETS[k] = [str(v).strip()]
    except Exception as e: console.print(f"‚ö†Ô∏è Load Tier1 Error: {e}", style="yellow")

TARGET_COMPETITORS_TIER2 = [] 
if os.path.exists(COMPETITORS_PATH):
    try:
        with open(COMPETITORS_PATH, "r", encoding="utf-8") as f:
            yaml_data = yaml.safe_load(f)
            if yaml_data and 'competitors' in yaml_data:
                TARGET_COMPETITORS_TIER2 = [str(x).strip() for x in yaml_data['competitors'] if x]
    except: pass

CLIENTS_TARGETS = {}
if os.path.exists(CLIENTS_PATH):
    try:
        with open(CLIENTS_PATH, "r", encoding="utf-8") as f:
            CLIENTS_TARGETS = yaml.safe_load(f) or {}
            for k in list(CLIENTS_TARGETS.keys()):
                if not CLIENTS_TARGETS[k]: del CLIENTS_TARGETS[k]
                elif not isinstance(CLIENTS_TARGETS[k], list): CLIENTS_TARGETS[k] = [str(CLIENTS_TARGETS[k])]
    except: pass

TARGET_UNIVERSITIES = ["‡∏ß‡πÑ‡∏•‡∏¢‡∏≠‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå", "Valaya Alongkorn Rajabhat University under the Royal Patronage"]  
TARGET_FACULTIES = ["‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á","Cosmetic Science"] 
TARGET_MAJORS = ["‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á", "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á","Cosmetic Science", "Cosmetics", "Cosmetic"]
SEARCH_KEYWORDS = ["‡∏ß‡πÑ‡∏•‡∏¢‡∏≠‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á","Cosmetic Valaya Alongkorn"]

KEYWORDS_CONFIG = {
    "NPD": {"titles": ["NPD", "R&D", "RD", "Research", "Development", "‡∏ß‡∏¥‡∏à‡∏±‡∏¢", "‡∏û‡∏±‡∏í‡∏ô‡∏≤", "Formulation", "‡∏™‡∏π‡∏ï‡∏£"]},
    "PCM": {"titles": ["PCM", "Production", "‡∏ú‡∏•‡∏¥‡∏ï", "Manufacturing", "Factory", "‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô", "QA", "QC"]},
    "Sales": {"titles": ["Sale", "Sales", "‡∏Ç‡∏≤‡∏¢", "AE", "BD", "Customer", "Telesale"]},
    "MKT": {"titles": ["MKT", "Marketing", "‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î", "Digital", "Content", "Media", "Ads"]},
    "Admin": {"titles": ["Admin", "‡∏ò‡∏∏‡∏£‡∏Å‡∏≤‡∏£", "‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ô‡∏á‡∏≤‡∏ô", "Coordinator", "Document", "‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"]},
    "HR": {"titles": ["HR", "Recruit", "‡∏™‡∏£‡∏£‡∏´‡∏≤", "‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•", "Training", "Payroll"]},
    "SCM": {"titles": ["SCM", "Supply Chain", "Logistic", "‡∏Ç‡∏ô‡∏™‡πà‡∏á", "Warehouse", "Stock", "Import", "Export"]},
    "PUR": {"titles": ["PUR", "Purchase", "‡∏à‡∏±‡∏î‡∏ã‡∏∑‡πâ‡∏≠", "Sourcing", "Buyer"]},
    "DATA": {"titles": ["Data", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "Analyst", "Statistic", "‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"]},
    "Present": {"titles": ["Present", "Speaker", "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏£", "Trainer"]},
    "IT": {"titles": ["IT", "Computer", "Software", "Programmer", "Developer"]},
    "RA": {"titles": ["RA", "Regulatory", "‡∏≠‡∏¢.", "FDA", "‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"]},
    "ACC": {"titles": ["ACC", "Account", "‡∏ö‡∏±‡∏ç‡∏ä‡∏µ", "Finance", "‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô", "Audit"]}
}

class JobThaiRowScraper:
    def __init__(self):
        console.rule("[bold cyan]üõ°Ô∏è JobThai Scraper (GitHub Actions Robust Edition)[/]")
        self.history_file = "notification_history_uni.json" 
        self.history_data = {}
        
        # Safe Directory Creation
        if not os.path.exists(RESUME_IMAGE_FOLDER): 
            try: os.makedirs(RESUME_IMAGE_FOLDER, exist_ok=True)
            except: pass
        
        if EMAIL_USE_HISTORY and os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f: self.history_data = json.load(f)
            except: self.history_data = {}

        if UserAgent: self.ua = UserAgent(browsers=['chrome'], os=['windows'])
        else: self.ua = None

        # --- üü¢ DRIVER CONFIG FOR GITHUB ACTIONS (SELENIUM STANDARD) ---
        opts = webdriver.ChromeOptions()
        
        # Headless Config
        opts.add_argument('--headless=new') # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö Headless ‡∏ö‡∏ô GitHub
        opts.add_argument('--window-size=1920,1080')
        opts.add_argument("--no-sandbox")
        opts.add_argument("--disable-dev-shm-usage")
        opts.add_argument("--disable-gpu")
        
        # Anti-Detection & Popup
        opts.add_argument("--disable-popup-blocking")
        opts.add_argument("--disable-notifications")
        opts.add_argument("--lang=th-TH")
        opts.add_argument("--disable-blink-features=AutomationControlled")
        
        # Fake User-Agent (Critical for JobThai)
        fake_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        opts.add_argument(f'--user-agent={fake_user_agent}')
        
        try:
            # ‡πÉ‡∏ä‡πâ ChromeDriverManager ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î Driver ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Chrome ‡∏ö‡∏ô GitHub Actions ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)
        except Exception as e:
            console.print(f"‚ùå Driver Init Error: {e}", style="error")
            raise e
        
        self.driver.set_page_load_timeout(60) 
        self.wait = WebDriverWait(self.driver, 20)
        self.total_profiles_viewed = 0 
        self.all_scraped_data = []

    def set_random_user_agent(self):
        if self.ua:
            try: self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {"userAgent": self.ua.random})
            except: pass

    def random_sleep(self, min_t=2.0, max_t=5.0): 
        time.sleep(random.uniform(min_t, max_t))

    def wait_for_page_load(self, timeout=15):
        try:
            WebDriverWait(self.driver, timeout).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
        except: pass

    def safe_click(self, selector, by=By.XPATH, timeout=10):
        # ... (‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏î‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß) ...
        try:
            element = WebDriverWait(self.driver, timeout).until(EC.element_to_be_clickable((by, selector)))
            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
            time.sleep(0.5)
            element.click()
            return True
        except:
            try:
                element = self.driver.find_element(by, selector)
                self.driver.execute_script("arguments[0].click();", element)
                return True
            except: return False
    
    def human_scroll(self):
        try:
            total_height = self.driver.execute_script("return document.body.scrollHeight")
            current_position = 0
            while current_position < total_height:
                scroll_step = random.randint(300, 700)
                current_position += scroll_step
                self.driver.execute_script(f"window.scrollTo(0, {current_position});")
                time.sleep(random.uniform(0.1, 0.4))
            self.driver.execute_script("window.scrollTo(0, 0);")
        except: pass

    def parse_thai_date_exact(self, date_str):
        # ... (Logic ‡πÄ‡∏î‡∏¥‡∏°) ...
        if not date_str: return None
        thai_months = {'‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': 1, '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': 2, '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': 3, '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': 4, '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': 5, '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': 6, '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': 7, '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': 8, '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': 9, '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': 10, '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': 11, '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': 12}
        try:
            date_str = date_str.strip()
            parts = date_str.split() 
            if len(parts) < 3: return None
            day = int(parts[0])
            month = thai_months.get(parts[1])
            year_be = int(parts[2])
            year_ad = year_be - 543
            return datetime.date(year_ad, month, day)
        except: return None

    # ==============================================================================
    # üî• STEP 1: ROBUST LOGIN (NO COOKIE, NO HAMMER)
    # ==============================================================================
    def step1_login(self):
        login_url = "https://www.jobthai.com/th/employer"
        max_retries = 5 
        
        for attempt in range(1, max_retries + 1):
            console.rule(f"[bold cyan]üîê Login Attempt {attempt}/{max_retries}[/]")
            try:
                self.driver.get(login_url)
                self.wait_for_page_load()
                
                # 1. Kill Popups / PDPA
                console.print("   üßπ Clearing Popups...", style="dim")
                try:
                    self.driver.execute_script("""
                        var pdpa = document.querySelector('#pdpa-consent-dialog button');
                        if(pdpa) pdpa.click();
                        var modal = document.querySelector('.modal-close-btn');
                        if(modal) modal.click();
                    """)
                    time.sleep(1)
                except: pass

                # 2. Force Switch Tab to Employer (JS Injection)
                console.print("   ‚ö° Injecting JS to switch tab...", style="info")
                try:
                    self.driver.execute_script("""
                        document.querySelectorAll('li[data-tab]').forEach(el => el.classList.remove('active'));
                        var tabEmp = document.querySelector('li[data-tab="employer"]');
                        if(tabEmp) tabEmp.classList.add('active');
                        
                        var formSeeker = document.getElementById('login-form-jobseeker');
                        if(formSeeker) formSeeker.style.display = 'none';
                        
                        var formEmp = document.getElementById('login-form-employer');
                        if(formEmp) formEmp.style.display = 'block';
                    """)
                    time.sleep(1)
                except Exception as e: console.print(f"‚ö†Ô∏è Tab switch warning: {e}", style="dim")

                # 3. Fill Username/Password
                console.print("   üìù Inputting credentials...", style="info")
                
                # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏à‡∏≠‡∏ä‡πà‡∏≠‡∏á Username ‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á interactable
                user_inp = WebDriverWait(self.driver, 10).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, "#login-form-username, input[name='username']"))
                )
                # ‡πÉ‡∏ä‡πâ ActionChains ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå
                ActionChains(self.driver).move_to_element(user_inp).click().perform()
                user_inp.clear()
                user_inp.send_keys(MY_USERNAME)
                
                pass_inp = self.driver.find_element(By.CSS_SELECTOR, "#login-form-password, input[name='password']")
                pass_inp.clear()
                pass_inp.send_keys(MY_PASSWORD)
                
                # 4. Submit
                console.print("   üöÄ Submitting...", style="info")
                pass_inp.send_keys(Keys.ENTER)
                time.sleep(2)
                
                # ‡∏ñ‡πâ‡∏≤‡∏Å‡∏î Enter ‡πÑ‡∏°‡πà‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á Click ‡∏õ‡∏∏‡πà‡∏°
                try:
                    btn = self.driver.find_element(By.CSS_SELECTOR, "#btn-login, button[type='submit']")
                    self.driver.execute_script("arguments[0].click();", btn)
                except: pass

                # 5. Verify Login
                console.print("   ‚è≥ Verifying...", style="dim")
                try:
                    WebDriverWait(self.driver, 20).until(
                        lambda d: "login" not in d.current_url or "findresume" in d.current_url
                    )
                    console.print(f"üéâ Login Success! (Attempt {attempt})", style="bold green")
                    return True
                except TimeoutException:
                    # Check Error Message
                    try:
                        err = self.driver.find_element(By.CSS_SELECTOR, ".error-message").text
                        console.print(f"   üõë Login Error Message: {err}", style="bold red")
                    except: pass
                    console.print("   ‚ùå Timeout: URL didn't change.", style="error")

            except Exception as e:
                console.print(f"   ‚ö†Ô∏è Exception: {e}", style="warning")
                try: self.driver.delete_all_cookies()
                except: pass
                
        console.print("‚ùå Login Failed after all attempts.", style="bold red")
        return False

    def step2_search(self, keyword):
        search_url = "https://www3.jobthai.com/findresume/findresume.php?l=th"
        console.print(f"2Ô∏è‚É£   ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '[bold]{keyword}[/]' ...", style="info")
        
        try:
            self.driver.get(search_url)
            self.wait_for_page_load()
            
            # ‡∏£‡∏≠‡∏ä‡πà‡∏≠‡∏á Search
            kw_element = WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.ID, "KeyWord"))
            )
            
            # ‡πÉ‡∏ä‡πâ JS ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
            self.driver.execute_script("arguments[0].value = arguments[1];", kw_element, keyword)
            
            # ‡∏Å‡∏î Search
            search_btn = self.driver.find_element(By.ID, "buttonsearch")
            self.driver.execute_script("arguments[0].click();", search_btn)
            
            console.print("   üîç ‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå...", style="dim")
            
            # ‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            try:
                WebDriverWait(self.driver, 15).until(
                    lambda d: "ResumeDetail" in d.page_source or "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" in d.page_source or "No data found" in d.page_source
                )
            except TimeoutException:
                console.print("   ‚ö†Ô∏è Search Timeout (‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏ô‡πá‡∏ï‡∏ä‡πâ‡∏≤)", style="warning")
                return False

            src = self.driver.page_source
            if "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" in src or "No data found" in src:
                console.print(f"   ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (0 Results)", style="warning")
                return True # ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏≠‡∏á
            
            console.print(f"   ‚úÖ ‡πÄ‡∏à‡∏≠‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤!", style="success")
            return True

        except Exception as e:
            console.print(f"‚ùå Search Error ({keyword}): {e}", style="error")
            return False

    def step3_collect_all_links(self):
        collected_links = []
        page_num = 1
        console.rule("[bold yellow]3Ô∏è‚É£  ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå[/]")
        
        while True:
            console.print(f"   üìÑ ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {page_num}...", style="info")
            try:
                # ‡∏£‡∏≠‡∏•‡∏¥‡∏á‡∏Å‡πå Resume
                try:
                    WebDriverWait(self.driver, 5).until(EC.presence_of_element_located((By.XPATH, "//a[contains(@href, 'ResumeDetail')]")))
                except: pass
                
                all_anchors = self.driver.find_elements(By.XPATH, "//a[contains(@href, 'ResumeDetail') or contains(@href, '/resume/')]")
                
                count_before = len(collected_links)
                for a in all_anchors:
                    try:
                        href = a.get_attribute("href")
                        if href and href not in collected_links:
                            collected_links.append(href)
                    except: continue
                
                new_count = len(collected_links) - count_before
                console.print(f"      -> ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°: {new_count} (‡∏£‡∏ß‡∏° {len(collected_links)})", style="success")

            except Exception as e:
                console.print(f"      ‚ùå Error ‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå: {e}", style="error")

            if len(collected_links) == 0: break
            if new_count == 0: break

            try:
                # ‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏° Next (‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢ selector)
                next_btns = self.driver.find_elements(By.XPATH, '//*[@id="content-l"]/div[2]/div[1]/table/tbody/tr/td[8]/a')
                found = False
                for btn in next_btns:
                    if "‡∏ñ‡∏±‡∏î‡πÑ‡∏õ" in btn.text or "Next" in btn.text or ">" in btn.text:
                        self.driver.execute_script("arguments[0].click();", btn)
                        found = True
                        break
                
                if not found and next_btns:
                     self.driver.execute_script("arguments[0].click();", next_btns[0])
                     found = True

                if found:
                    page_num += 1
                    time.sleep(3)
                else: break
            except: break
            
        console.print(f"[bold green]üì¶ ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°: {len(collected_links)} ‡∏•‡∏¥‡∏á‡∏Å‡πå[/]")
        return collected_links

    # ==============================================================================
    # üïµÔ∏è DATA EXTRACTION (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°)
    # ==============================================================================
    def scrape_detail_from_json(self, url, keyword, progress_console=None):
        printer = progress_console if progress_console else console
        self.set_random_user_agent()
        
        load_success = False
        for _ in range(3):
            try:
                self.driver.get(url)
                self.wait_for_page_load()
                load_success = True
                break 
            except: self.random_sleep(5, 10)

        if not load_success: return None, 999, None
        
        try: self.human_scroll() 
        except: pass
        self.random_sleep(2.0, 4.0)
        
        data = {'Link': url}
        try: full_text = self.driver.find_element(By.CSS_SELECTOR, "#mainTableTwoColumn").text
        except: full_text = ""
        
        def get_val(sel, xpath=False):
            try:
                elem = self.driver.find_element(By.XPATH, sel) if xpath else self.driver.find_element(By.CSS_SELECTOR, sel)
                return elem.text.strip()
            except: return ""

        # --- üéì Degree Parsing ---
        edu_tables_xpath = '//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[7]/td[2]/table'
        try:
            edu_tables = self.driver.find_elements(By.XPATH, edu_tables_xpath)
            total_degrees = len(edu_tables)
        except: total_degrees = 0
        
        matched_uni = ""; matched_faculty = ""; matched_major = ""; is_qualified = False
        highest_degree_text = "-"; max_degree_score = -1
        degree_score_map = {"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÄ‡∏≠‡∏Å": 3, "‡∏î‡∏∏‡∏©‡∏é‡∏µ‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï": 3, "Doctor": 3, "Ph.D": 3, "‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó": 2, "‡∏°‡∏´‡∏≤‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï": 2, "Master": 2, "‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ": 1, "‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï": 1, "Bachelor": 1}
        
        def check_fuzzy(scraped_text, target_list, threshold=85):
            if not target_list: return True
            if not scraped_text: return False
            best_score = 0
            for target in target_list:
                score = fuzz.partial_ratio(target.lower(), scraped_text.lower())
                if score > best_score: best_score = score
            return best_score >= threshold

        for i in range(1, total_degrees + 1):
            base_xpath = f'//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[7]/td[2]/table[{i}]'
            curr_uni = get_val(f'{base_xpath}/tbody/tr[2]/td/div', True)
            if not curr_uni: curr_uni = get_val(f'{base_xpath}/tbody/tr[1]/td/div', True)
            
            curr_degree = get_val(f'{base_xpath}//td[contains(., "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤")]/following-sibling::td[1]', True)
            if not curr_degree: curr_degree = get_val(f'{base_xpath}/tbody/tr[1]/td', True)
            
            curr_faculty = get_val(f'{base_xpath}//td[contains(., "‡∏Ñ‡∏ì‡∏∞")]/following-sibling::td[1]', True)
            curr_major = get_val(f'{base_xpath}//td[contains(., "‡∏™‡∏≤‡∏Ç‡∏≤")]/following-sibling::td[1]', True)
            
            score = 0
            for key, val in degree_score_map.items():
                if key in str(curr_degree): score = val; break
            if score > max_degree_score: max_degree_score = score; highest_degree_text = curr_degree
            elif score == max_degree_score and highest_degree_text == "-": highest_degree_text = curr_degree

            if not is_qualified:
                uni_pass = check_fuzzy(curr_uni, TARGET_UNIVERSITIES)
                fac_pass = check_fuzzy(curr_faculty, TARGET_FACULTIES)
                major_pass = check_fuzzy(curr_major, TARGET_MAJORS)
                if uni_pass and (fac_pass or major_pass):
                    is_qualified = True; matched_uni = curr_uni; matched_faculty = curr_faculty; matched_major = curr_major

        if not is_qualified: return None, 999, None # Filter Logic
        
        data['‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤'] = highest_degree_text; data['‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢'] = matched_uni; data['‡∏Ñ‡∏ì‡∏∞'] = matched_faculty; data['‡∏™‡∏≤‡∏Ç‡∏≤'] = matched_major
        data['‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£'] = get_val("#ResumeViewDiv [align='left'] span.white")
        
        # --- üñºÔ∏è Image Saving (Safe Mode) ---
        try:
            img_element = self.driver.find_element(By.ID, "DefaultPictureResume2Column")
            app_id_clean = data['‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£'].strip() if data['‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£'] else f"unknown_{int(time.time())}"
            img_filename = f"{app_id_clean}.png"
            if not os.path.exists(RESUME_IMAGE_FOLDER): 
                try: os.makedirs(RESUME_IMAGE_FOLDER, exist_ok=True)
                except: pass
            
            if os.path.exists(RESUME_IMAGE_FOLDER):
                save_path = os.path.join(RESUME_IMAGE_FOLDER, img_filename)
                img_element.screenshot(save_path)
                data['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'] = save_path
            else: data['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'] = ""
        except: data['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'] = ""

        raw_update_date = get_val('//*[@id="ResumeViewDiv"]/table/tbody/tr[2]/td[3]/span[2]', xpath=True)
        
        def calculate_last_update(date_str):
            if not date_str: return "-"
            try:
                parts = date_str.split()
                if len(parts) < 3: return "-"
                day = int(parts[0])
                thai_months = {'‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': 1, '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': 2, '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': 3, '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': 4, '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': 5, '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': 6, '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': 7, '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': 8, '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': 9, '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': 10, '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': 11, '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': 12}
                month = thai_months.get(parts[1], 1)
                year_ad = int(parts[2]) - 543
                update_dt = datetime.datetime(year_ad, month, day)
                diff = relativedelta(datetime.datetime.now(), update_dt)
                txt = []
                if diff.years > 0: txt.append(f"{diff.years}‡∏õ‡∏µ")
                if diff.months > 0: txt.append(f"{diff.months}‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
                if diff.days > 0: txt.append(f"{diff.days}‡∏ß‡∏±‡∏ô")
                return " ".join(txt) if txt else "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ"
            except: return "-"
            
        data['‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î'] = calculate_last_update(raw_update_date)
        data['‡∏ä‡∏∑‡πà‡∏≠'] = get_val("#mainTableTwoColumn td > span.head1")
        data['‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•'] = get_val("span.black:nth-of-type(3)")
        
        age_match = re.search(r"‡∏≠‡∏≤‡∏¢‡∏∏\s*[:]?\s*(\d+)", full_text)
        data['‡∏≠‡∏≤‡∏¢‡∏∏'] = age_match.group(1) if age_match else ""
        data['‡πÄ‡∏û‡∏®'] = re.search(r"‡πÄ‡∏û‡∏®\s*[:]?\s*(‡∏ä‡∏≤‡∏¢|‡∏´‡∏ç‡∏¥‡∏á|Male|Female)", full_text).group(1) if re.search(r"‡πÄ‡∏û‡∏®", full_text) else ""
        data['‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£'] = get_val("#mainTableTwoColumn div:nth-of-type(6) span.black")
        data['Email'] = get_val("#mainTableTwoColumn a")
        data['‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà'] = get_val("#mainTableTwoColumn div:nth-of-type(1) span.head1")
        data['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà'] = get_val("#mainTableTwoColumn table [width][align='left'] div span.headNormal")
        
        pos1 = get_val('//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[5]/td[2]/table/tbody/tr[3]/td/span[2]', xpath=True)
        pos2 = get_val('//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[5]/td[2]/table/tbody/tr[3]/td/span[4]', xpath=True)
        pos3 = get_val('//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[5]/td[2]/table/tbody/tr[3]/td/span[6]', xpath=True)
        data['‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_1'] = pos1; data['‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_2'] = pos2; data['‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_3'] = pos3
        combined_positions = ", ".join([p for p in [pos1, pos2, pos3] if p])
        data['‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£'] = get_val("//td[contains(., '‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£')]/following-sibling::td[1]", True)
        
        salary_min_txt = "-"; salary_max_txt = "-"
        raw_salary = data.get('‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£', '')
        try:
            if raw_salary and '‡∏õ‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•' not in str(raw_salary):
                s = str(raw_salary).lower().replace(',', '')
                s = re.sub(r'(\d+(\.\d+)?)\s*k', lambda m: str(float(m.group(1)) * 1000), s)
                nums = [float(n) for n in re.findall(r'\d+(?:\.\d+)?', s)]
                if nums:
                    mn, mx = nums[0], nums[0]
                    if len(nums) >= 2: mn, mx = nums[0], nums[1]
                    if mx > 1000 and mn < 1000 and mn > 0: mn *= 1000
                    salary_min_txt = f"{int(mn):,}"; salary_max_txt = f"{int(mx):,}"
        except: pass
        data['Salary_Min'] = salary_min_txt; data['Salary_Max'] = salary_max_txt

        all_work_history = []
        try:
            if "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô/‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô" in full_text:
                history_text = full_text.split("‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô/‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô")[1].split("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ")[0]
            else: history_text = ""
            thai_months_str = "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°"
            raw_chunks = re.split(f"({thai_months_str})\\s+\\d{{4}}\\s+-\\s+", history_text)
            jobs = []
            if len(raw_chunks) > 1:
                for k in range(1, len(raw_chunks), 2):
                    if k+1 < len(raw_chunks): jobs.append(raw_chunks[k] + raw_chunks[k+1]) 
            i = 0
            while True:
                check_xpath = f'//*[@id="mainTableTwoColumn"]/tbody/tr/td[2]/table/tbody/tr[2]/td[2]/table[{i+1}]'
                try:
                    if len(self.driver.find_elements(By.XPATH, check_xpath)) == 0: break
                except: break
                suffix = f"_{i+1}"
                company = get_val(f'{check_xpath}/tbody/tr[3]/td/div/span', True)
                if not company: company = get_val(f'{check_xpath}/tbody/tr[3]/td', True)
                if i < len(jobs):
                    block = jobs[i]
                    if not company:
                        comp_match = re.search(r"^.*(‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó|Ltd|Inc|Group|Organization|‡∏´‡∏à‡∏Å|Limited).*$", block, re.MULTILINE | re.IGNORECASE)
                        company = comp_match.group(0).strip() if comp_match else ""
                data[f'‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô{suffix}'] = company
                if company: all_work_history.append(company.strip())
                i += 1
        except: pass
        
        competitor_str = ", ".join(all_work_history)
        data['‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á'] = competitor_str

        today_date = datetime.date.today()
        update_date = self.parse_thai_date_exact(raw_update_date)
        days_diff = 999
        if update_date: days_diff = (today_date - update_date).days

        full_name = f"{data.get('‡∏ä‡∏∑‡πà‡∏≠', '')} {data.get('‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '')}"
        person_data = {
            "keyword": keyword, 
            "company": competitor_str,
            "degree": highest_degree_text,
            "salary_min": salary_min_txt,
            "salary_max": salary_max_txt,
            "id": data.get('‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£', '').strip(),
            "name": full_name,
            "age": data.get('‡∏≠‡∏≤‡∏¢‡∏∏', '-'),
            "positions": combined_positions, 
            "last_update": data['‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î'],
            "link": url,
            "image_path": data.get('‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û', '')
        }

        printer.print(f"   üî• ‡πÄ‡∏à‡∏≠: {highest_degree_text} | ‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢: {matched_uni} | {days_diff} ‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô", style="bold green")
        return data, days_diff, person_data

    # --- EMAIL & SHEETS (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
    def send_single_email(self, subject_prefix, people_list, col_header="‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó"):
        sender = os.getenv("EMAIL_SENDER")
        password = os.getenv("EMAIL_PASSWORD")
        receiver_list = []
        if MANUAL_EMAIL_RECEIVERS and len(MANUAL_EMAIL_RECEIVERS) > 0: receiver_list = MANUAL_EMAIL_RECEIVERS
        else:
             rec_env = os.getenv("EMAIL_RECEIVER")
             if rec_env: receiver_list = [rec_env]
        
        if not sender or not password or not receiver_list: return

        if "‡∏™‡∏£‡∏∏‡∏õ" in subject_prefix or "HOT" in subject_prefix: subject = subject_prefix
        elif len(people_list) > 1: subject = f"üî• {subject_prefix} ({len(people_list)} ‡∏Ñ‡∏ô)"
        else: subject = subject_prefix 

        body_html = f"""
        <html>
        <head>
        <style>
            table {{ border-collapse: collapse; width: 100%; font-size: 14px; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            tr:nth-child(even) {{ background-color: #f9f9f9; }}
            .btn {{
                background-color: #28a745; 
                color: #ffffff !important; 
                padding: 5px 10px;
                text-align: center; 
                text-decoration: none; 
                display: inline-block;
                border-radius: 4px; 
                font-size: 12px;
                font-weight: bold;
            }}
            .btn:hover {{ color: #ffffff !important; }}
        </style>
        </head>
        <body>
            <h3>{subject}</h3>
            <table>
                <tr>
                    <th style="width: 10%;">‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û</th>
                    <th style="width: 15%;">{col_header}</th>
                    <th style="width: 10%;">‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î</th>
                    <th style="width: 10%;">‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£</th>
                    <th style="width: 15%;">‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•</th>
                    <th style="width: 5%;">‡∏≠‡∏≤‡∏¢‡∏∏</th>
                    <th style="width: 15%;">‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏±‡∏Ñ‡∏£</th>
                    <th style="width: 8%;">‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥</th> <th style="width: 8%;">‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î</th> <th style="width: 10%;">‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î</th>
                    <th style="width: 10%;">‡∏•‡∏¥‡∏á‡∏Å‡πå</th>
                </tr>
        """
        
        images_to_attach = []
        for person in people_list:
            cid_id = f"img_{person['id']}"
            if person['image_path'] and os.path.exists(person['image_path']):
                img_html = f'<img src="cid:{cid_id}" width="80" style="border-radius: 5px;">'
                images_to_attach.append({'cid': cid_id, 'path': person['image_path']})
            else:
                img_html = '<span style="color:gray;">No Image</span>'

            company_display = person['company']
            company_style = "font-weight: bold;" if (company_display == "University Target" or company_display == "-") else "font-weight: normal;"
            if company_display == "University Target" or company_display == "-": company_display = "-"

            body_html += f"""
                <tr>
                    <td style="text-align: center;">{img_html}</td>
                    <td style="{company_style}">{company_display}</td>
                    <td>{person.get('degree', '-')}</td> 
                    <td>{person['id']}</td>
                    <td>{person['name']}</td>
                    <td>{person['age']}</td>
                    <td>{person['positions']}</td>
                    <td>{person.get('salary_min', '-')}</td> <td>{person.get('salary_max', '-')}</td> <td>{person['last_update']}</td>
                    <td style="text-align: center;">
                        <a href="{person['link']}" target="_blank" class="btn">‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡∏π</a>
                    </td>
                </tr>
            """
            
        body_html += "</table><br><p><i>‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ JobThai Scraper</i></p></body></html>"

        try:
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(sender, password)
            
            msg_root = MIMEMultipart('related')
            msg_root['From'] = sender
            msg_root['Subject'] = subject
            
            msg_alternative = MIMEMultipart('alternative')
            msg_root.attach(msg_alternative)
            msg_alternative.attach(MIMEText(body_html, 'html'))
            
            for img_data in images_to_attach:
                try:
                    with open(img_data['path'], 'rb') as f:
                        msg_img = MIMEImage(f.read())
                        msg_img.add_header('Content-ID', f"<{img_data['cid']}>")
                        msg_img.add_header('Content-Disposition', 'inline', filename=os.path.basename(img_data['path']))
                        msg_root.attach(msg_img)
                except: pass

            for rec in receiver_list:
                if 'To' in msg_root: del msg_root['To']
                msg_root['To'] = rec
                server.send_message(msg_root)
                console.print(f"   ‚úÖ ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏• '{subject}' -> {rec}", style="success")
            server.quit()
        except Exception as e:
            console.print(f"‚ùå ‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}", style="error")

    def send_batch_email(self, batch_candidates, keyword):
        self.send_single_email(f"‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏£‡∏≤‡∏¢‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå: {keyword} ({len(batch_candidates)} ‡∏Ñ‡∏ô)", batch_candidates)

    def save_to_google_sheets(self):
        if not self.all_scraped_data:
            console.print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å", style="yellow")
            return

        console.rule("[bold green]üìä ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏∂‡πâ‡∏ô Google Sheets[/]")
        try:
            if not G_SHEET_KEY_JSON or not G_SHEET_NAME:
                console.print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Key ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå Google Sheet", style="error")
                return

            creds_dict = json.loads(G_SHEET_KEY_JSON)
            scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
            client = gspread.authorize(creds)
            
            sheet = client.open(G_SHEET_NAME)
            today_str = datetime.datetime.now().strftime("%d-%m-%Y")
            try:
                worksheet = sheet.worksheet(today_str)
            except:
                worksheet = sheet.add_worksheet(title=today_str, rows="100", cols="20")
                headers = [
                    "Link", "Keyword", "‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£", "‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•", "‡∏≠‡∏≤‡∏¢‡∏∏", "‡πÄ‡∏û‡∏®", 
                    "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£", "Email", "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà", "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢", "‡∏Ñ‡∏ì‡∏∞", "‡∏™‡∏≤‡∏Ç‡∏≤",
                    "‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏±‡∏Ñ‡∏£", "‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠ (Raw)", "‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î", "‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î",
                    "‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á", "‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"
                ]
                worksheet.append_row(headers)

            data_rows = []
            for item in self.all_scraped_data:
                row = [
                    item.get('Link', ''), item.get('Keyword', ''), item.get('‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£', ''),
                    f"{item.get('‡∏ä‡∏∑‡πà‡∏≠','')} {item.get('‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•','')}", item.get('‡∏≠‡∏≤‡∏¢‡∏∏', ''), item.get('‡πÄ‡∏û‡∏®', ''),
                    re.sub(r'\D', '', str(item.get('‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£', ''))), str(item.get('Email', '')).replace('Click', '').strip(),
                    item.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà', ''), item.get('‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤', ''), item.get('‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢', ''),
                    item.get('‡∏Ñ‡∏ì‡∏∞', ''), item.get('‡∏™‡∏≤‡∏Ç‡∏≤', ''),
                    f"{item.get('‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_1','')} {item.get('‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_2','')}",
                    item.get('‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£', ''), item.get('Salary_Min', '-'), item.get('Salary_Max', '-'), 
                    item.get('‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á', ''), item.get('‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î', '')
                ]
                data_rows.append(row)
            
            if data_rows:
                worksheet.append_rows(data_rows)
                console.print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(data_rows)} ‡πÅ‡∏ñ‡∏ß ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!", style="bold green")
                
        except Exception as e:
            console.print(f"‚ùå Google Sheets Error: {e}", style="error")

    def run(self):
        self.email_report_list = []
        if not self.step1_login(): return
        
        today = datetime.date.today()
        is_monday = (today.weekday() == 0)
        is_manual_run = (os.getenv("GITHUB_EVENT_NAME") == "workflow_dispatch")
        
        console.print(f"üìÖ Status Check: Monday? [{'Yes' if is_monday else 'No'}] | Manual? [{'Yes' if is_manual_run else 'No'}]", style="bold yellow")
        
        for index, keyword in enumerate(SEARCH_KEYWORDS):
            console.rule(f"[bold magenta]üîç ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏ó‡∏µ‡πà {index+1}/{len(SEARCH_KEYWORDS)}: {keyword}[/]")
            
            current_keyword_batch = []
            if self.step2_search(keyword):
                links = self.step3_collect_all_links()
                if links:
                    console.print(f"\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏π‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• '{keyword}' ({len(links)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£) ...")
                    with Progress(
                        SpinnerColumn(), TextColumn("[progress.description]{task.description}"),
                        BarColumn(), TaskProgressColumn(), TimeElapsedColumn(), TimeRemainingColumn(),
                        console=console
                    ) as progress:
                        task_id = progress.add_task(f"[cyan]Processing...", total=len(links))
                        
                        for i, link in enumerate(links):
                            if self.total_profiles_viewed > 0 and self.total_profiles_viewed % 33 == 0:
                                progress.console.print(f"[yellow]‚òï ‡∏Ñ‡∏£‡∏ö {self.total_profiles_viewed} ‡∏Ñ‡∏ô... ‡∏û‡∏±‡∏Å 4 ‡∏ô‡∏≤‡∏ó‡∏µ[/]")
                                time.sleep(240)

                            try:
                                d, days_diff, person_data = self.scrape_detail_from_json(link, keyword, progress_console=progress.console)
                                self.total_profiles_viewed += 1 
                                
                                if d is not None:
                                    d['Keyword'] = keyword
                                    self.all_scraped_data.append(d)
                                    
                                    # Logic ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏• (Hot / Weekly)
                                    should_add = False
                                    if days_diff <= 30:
                                        should_add = True
                                        if EMAIL_USE_HISTORY and person_data['id'] in self.history_data:
                                            try:
                                                last_notify = datetime.datetime.strptime(self.history_data[person_data['id']], "%Y-%m-%d").date()
                                                if (today - last_notify).days < 7: should_add = False
                                            except: pass
                                        if should_add: current_keyword_batch.append(person_data)

                                    if days_diff <= 1:
                                        should_hot = True
                                        if EMAIL_USE_HISTORY and person_data['id'] in self.history_data:
                                            try:
                                                 last_notify = datetime.datetime.strptime(self.history_data[person_data['id']], "%Y-%m-%d").date()
                                                 if (today - last_notify).days < 1: should_hot = False
                                            except: pass
                                        if should_hot:
                                            hot_subject = f"üî• [HOT] ‡∏û‡∏ö‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏î‡πà‡∏ß‡∏ô ({keyword}): {person_data['name']}"
                                            progress.console.print(f"   üö® ‡∏û‡∏ö‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ HOT -> ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!", style="bold red")
                                            self.send_single_email(hot_subject, [person_data], col_header="‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó")
                                            if EMAIL_USE_HISTORY: self.history_data[person_data['id']] = str(today)

                                    if days_diff > 30 and (is_monday or is_manual_run):
                                        if current_keyword_batch:
                                             progress.console.print(f"\n[bold green]üì® ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏•‡∏™‡∏£‡∏∏‡∏õ ({len(current_keyword_batch)} ‡∏Ñ‡∏ô)![/]")
                                             self.send_batch_email(current_keyword_batch, keyword)
                                             if EMAIL_USE_HISTORY:
                                                 for p in current_keyword_batch: self.history_data[p['id']] = str(today)
                                             current_keyword_batch = []

                            except Exception as e: progress.console.print(f"[bold red]‚ùå Error Link {i+1}: {e}[/]")
                            progress.advance(task_id)
                
                if current_keyword_batch and (is_monday or is_manual_run):
                    self.send_batch_email(current_keyword_batch, keyword)
                    if EMAIL_USE_HISTORY:
                         for p in current_keyword_batch: self.history_data[p['id']] = str(today)

            console.print("‚è≥ ‡∏û‡∏±‡∏Å 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ...", style="dim")
            time.sleep(3)
        
        self.save_to_google_sheets()
        self.save_history()
        console.rule("[bold green]üèÅ ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô[/]")
        try: self.driver.quit()
        except: pass

if __name__ == "__main__":
    console.print("[bold green]üöÄ Starting JobThai Scraper (Robust Edition)...[/]")
    if not MY_USERNAME or not MY_PASSWORD:
        console.print(f"\n[bold red]‚ùå [CRITICAL ERROR] ‡πÑ‡∏°‡πà‡∏û‡∏ö User/Pass ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env[/]")
        exit()
    scraper = JobThaiRowScraper()
    scraper.run()
